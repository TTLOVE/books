#!/usr/bin/env python
# -*- coding: utf-8 -*-

import re
import os
import zipfile
import xml.etree.ElementTree as ET

def split_chapters_robust(text):
    """
    æ ¹æ®"ç¬¬ä¸€ç« \näººç±»æ‚²ä¼¤çš„åŸå‹"æ ¼å¼åˆ‡åˆ†ç« èŠ‚
    ç« èŠ‚ç¼–å·å’Œç« èŠ‚åç§°åˆ†åˆ«åœ¨ä¸åŒè¡Œ
    """
    lines = text.splitlines()
    chapters = []
    current_title = ""
    current_content_lines = []

    # åŒ¹é…ç« èŠ‚ç¼–å·æ ¼å¼ï¼Œå¦‚"ç¬¬ä¸€ç« "ã€"ç¬¬äºŒç« "ã€"ç¬¬Xç« "ç­‰
    chapter_number_pattern = re.compile(r'^\s*ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+[ç« èŠ‚]\s*$')

    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚ç¼–å·è¡Œ
        if chapter_number_pattern.match(stripped):
            # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¸ºæ ‡é¢˜å†…å®¹
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # å¦‚æœä¸‹ä¸€è¡Œéç©ºä¸”ä¸æ˜¯å¦ä¸€ä¸ªç« èŠ‚ç¼–å·ï¼Œåˆ™å°†å…¶ä½œä¸ºç« èŠ‚æ ‡é¢˜
                if next_line and not chapter_number_pattern.match(next_line):
                    # ä¿å­˜ä¸Šä¸€ç« èŠ‚ï¼ˆå¦‚æœæœ‰å†…å®¹ï¼‰
                    if current_title or current_content_lines:
                        chapters.append({
                            "title": current_title,
                            "content": "\n".join(current_content_lines).strip()
                        })
                    
                    # è®¾ç½®æ–°ç« èŠ‚æ ‡é¢˜ï¼Œè·³è¿‡ç¼–å·å’Œæ ‡é¢˜ä¸¤è¡Œ
                    current_title = next_line
                    i += 2  # è·³è¿‡ç« èŠ‚ç¼–å·è¡Œå’Œæ ‡é¢˜è¡Œ
                    current_content_lines = []
                    continue
        
        # æ·»åŠ å½“å‰è¡Œåˆ°ç« èŠ‚å†…å®¹ï¼ˆå¦‚æœä¸æ˜¯ç« èŠ‚ç¼–å·è¡Œï¼‰
        current_content_lines.append(line)
        i += 1

    # æ·»åŠ æœ€åä¸€ç« èŠ‚
    if current_title or current_content_lines:
        chapters.append({
            "title": current_title or "å‰è¨€",
            "content": "\n".join(current_content_lines).strip()
        })

    return chapters

def extract_text_from_docx(file_path):
    """
    ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    DOCX å®é™…ä¸Šæ˜¯ ZIP æ ¼å¼çš„å‹ç¼©åŒ…ï¼ŒåŒ…å« XML æ–‡ä»¶
    """
    try:
        with zipfile.ZipFile(file_path, 'r') as docx_zip:
            # è¯»å–ä¸»æ–‡æ¡£å†…å®¹
            content_xml = docx_zip.read('word/document.xml')
            tree = ET.fromstring(content_xml)
            
            # å®šä¹‰å‘½åç©ºé—´
            namespaces = {
                'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'
            }
            
            # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
            paragraphs = []
            for paragraph in tree.iterfind('.//w:p', namespaces):
                texts = []
                for text_elem in paragraph.iterfind('.//w:t', namespaces):
                    if text_elem is not None and text_elem.text:
                        texts.append(text_elem.text)
                if texts:
                    paragraphs.append(''.join(texts))
            
            return '\n'.join(paragraphs)
    except Exception as e:
        print(f"âŒ æ— æ³•ä» DOCX æ–‡ä»¶æå–æ–‡æœ¬: {e}")
        return None

def process_yilian_docx():
    """
    å¤„ç†ä¾æ‹ä¸‰éƒ¨æ›²â€¢ç¬¬äºŒå·åˆ†ç¦».docx æ–‡ä»¶
    """
    docx_path = "./ä¾æ‹ä¸‰éƒ¨æ›²â€¢ç¬¬äºŒå·åˆ†ç¦».docx"
    
    print(f"ğŸ“– æ­£åœ¨ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬: {docx_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(docx_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docx_path}")
        return
    
    # ä» DOCX æ–‡ä»¶æå–æ–‡æœ¬
    text_content = extract_text_from_docx(docx_path)
    
    if text_content is None:
        print("âŒ æ— æ³•æå– DOCX æ–‡ä»¶å†…å®¹")
        return
    
    print(f"âœ… æˆåŠŸæå–æ–‡æœ¬ï¼Œå…± {len(text_content)} ä¸ªå­—ç¬¦")
    
    # æŒ‰ç« èŠ‚æ¨¡å¼åˆ‡åˆ†æ–‡æ¡£
    print("âœ‚ï¸ æ­£åœ¨æŒ‰'ç¬¬ä¸€ç« \\näººç±»æ‚²ä¼¤çš„åŸå‹'æ ¼å¼åˆ‡åˆ†ç« èŠ‚...")
    chapters = split_chapters_robust(text_content)

    print(f"âœ… æˆåŠŸè¯†åˆ«å‡º {len(chapters)} ä¸ªç« èŠ‚")
    print("=" * 80)
    print("ğŸ“‹ ç« èŠ‚åˆ‡åˆ†ç»“æœ:")
    print("=" * 80)
    
    for i, chapter in enumerate(chapters, 1):
        title = chapter['title']
        content_length = len(chapter['content'])
        preview = chapter['content'][:100] + "..." if len(chapter['content']) > 100 else chapter['content']
        
        print(f"\nç¬¬ {i:2d} ç« :")
        print(f"  æ ‡é¢˜: {title}")
        print(f"  å†…å®¹é•¿åº¦: {content_length} å­—ç¬¦")
        print(f"  å†…å®¹é¢„è§ˆ: {preview}")
        print("-" * 60)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ€»è®¡: {len(chapters)} ä¸ªç« èŠ‚")
    total_chars = sum(len(ch['content']) for ch in chapters)
    print(f"æ€»å†…å®¹å­—ç¬¦æ•°: {total_chars}")
    
    print("\nâ€”" * 80)
    print("æ‰€æœ‰ç« èŠ‚æ ‡é¢˜åˆ—è¡¨:")
    print("â€”" * 80)
    for i, chapter in enumerate(chapters, 1):
        print(f"{i:3d}. {chapter['title']}")
    

if __name__ == "__main__":
    process_yilian_docx()