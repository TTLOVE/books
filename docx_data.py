#!/usr/bin/env python
# -*- coding: utf-8 -*-

import re
import os
import json
from aiClient import get_ai_response

def split_chapters_by_pattern(text):
    """
    æ ¹æ®"ç¬¬ä¸€ç« \näººç±»æ‚²ä¼¤çš„åŸå‹"æ ¼å¼åˆ‡åˆ†ç« èŠ‚
    ç« èŠ‚ç¼–å·å’Œç« èŠ‚åç§°åˆ†åˆ«åœ¨ä¸åŒè¡Œ
    """
    lines = text.splitlines()
    chapters = []
    current_title = ""
    current_content_lines = []

    # åŒ¹é…ç« èŠ‚ç¼–å·æ ¼å¼ï¼Œå¦‚"ç¬¬ä¸€ç« "ã€"ç¬¬äºŒç« "ç­‰ï¼ˆå•ç‹¬ä¸€è¡Œï¼‰
    chapter_number_pattern = re.compile(
        r'^\s*ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+[ç« èŠ‚]\s*$',
        re.UNICODE
    )

    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        if chapter_number_pattern.match(line):
            # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¸ºç« èŠ‚æ ‡é¢˜
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # å¦‚æœä¸‹ä¸€è¡Œéç©ºä¸”ä¸æ˜¯å¦ä¸€ä¸ªç« èŠ‚ç¼–å·ï¼Œåˆ™è®¤ä¸ºæ˜¯ç« èŠ‚æ ‡é¢˜
                if next_line and not chapter_number_pattern.match(next_line):
                    # ä¿å­˜ä¸Šä¸€ç« èŠ‚ï¼ˆå¦‚æœæœ‰å†…å®¹ï¼‰
                    if current_title or current_content_lines:
                        chapters.append({
                            "title": current_title,
                            "content": "\n".join(current_content_lines).strip()
                        })
                    
                    # è®¾ç½®æ–°ç« èŠ‚æ ‡é¢˜ï¼Œè·³è¿‡ç« èŠ‚ç¼–å·å’Œæ ‡é¢˜ä¸¤è¡Œ
                    current_title = next_line
                    i += 2  # è·³è¿‡ç« èŠ‚ç¼–å·è¡Œå’Œæ ‡é¢˜è¡Œ
                    current_content_lines = []
                    continue
                else:
                    # å¦‚æœä¸‹ä¸€è¡Œæ˜¯å¦ä¸€ä¸ªç« èŠ‚ç¼–å·æˆ–ä¸ºç©ºï¼Œåˆ™å½“å‰è¡Œå¯èƒ½åªæ˜¯æ™®é€šå†…å®¹
                    current_content_lines.append(lines[i])
            else:
                # å¦‚æœå½“å‰è¡Œæ˜¯æœ€åä¸€æ¡ä¸”æ²¡æœ‰ä¸‹ä¸€è¡Œæ ‡é¢˜ï¼Œåˆ™å¯èƒ½åªæ˜¯æ™®é€šå†…å®¹
                current_content_lines.append(lines[i])
            i += 1
        else:
            # ä¸æ˜¯ç« èŠ‚ç¼–å·è¡Œï¼Œæ·»åŠ åˆ°å½“å‰å†…å®¹
            current_content_lines.append(lines[i])
            i += 1

    # æ·»åŠ æœ€åä¸€ç« èŠ‚
    if current_title or current_content_lines:
        chapters.append({
            "title": current_title or "å‰è¨€",
            "content": "\n".join(current_content_lines).strip()
        })

    return chapters


def extract_text_from_docx(file_path):
    """
    ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    """
    try:
        import zipfile
        import xml.etree.ElementTree as ET
        
        with zipfile.ZipFile(file_path, 'r') as docx_zip:
            # è¯»å–ä¸»æ–‡æ¡£å†…å®¹
            content_xml = docx_zip.read('word/document.xml')
            tree = ET.fromstring(content_xml)
            
            # å®šä¹‰å‘½åç©ºé—´
            namespaces = {
                'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'
            }
            
            # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
            paragraphs = []
            for paragraph in tree.iterfind('.//w:p', namespaces):
                texts = []
                for text_elem in paragraph.iterfind('.//w:t', namespaces):
                    if text_elem is not None and text_elem.text:
                        texts.append(text_elem.text)
                if texts:
                    paragraphs.append(''.join(texts))
            
            return '\n'.join(paragraphs)
    except Exception as e:
        print(f"âŒ æ— æ³•ä» DOCX æ–‡ä»¶æå–æ–‡æœ¬: {e}")
        return None

def get_title_and_page(title):
    """
    è·å–æ ‡é¢˜å’Œé¡µæ•°
    """
    page = 0
    # åŒ¹é…æ ‡é¢˜åç§°å’Œé¡µæ•°ä¿¡æ¯,æ ‡é¢˜å¯èƒ½ä¸ºï¼šäººç±»æ‚²ä¼¤çš„åŸå‹   003ï¼Œéœ€è¦è·å–æ ‡é¢˜åç§°å’Œé¡µæ•°ä¿¡æ¯
    parts = re.split(r'\s+', title.strip(), maxsplit=1)
    if len(parts) > 1:
        title = parts[0]
        page = parts[1]
        page = page.replace('.', '').replace('/', '1')

        # åˆ¤æ–­æ˜¯å¦å­˜åœ¨æ•°å­—
        if re.search(r'\d', page):
            page = int(page)
        else:
            title = title + " " + page
            page = 0
    else:
        title = re.sub(r'\d+', '', title)

    return title, page

def process_yilian_docx():
    """
    å¤„ç†ä¾æ‹ä¸‰éƒ¨æ›²â€¢ç¬¬äºŒå·åˆ†ç¦».docx æ–‡ä»¶å¹¶è¾“å‡ºåˆ‡åˆ†ä¿¡æ¯
    """
    docx_path = "./ä¾æ‹ä¸‰éƒ¨æ›²â€¢ç¬¬äºŒå·åˆ†ç¦».docx"
    
    print(f"ğŸ“– æ­£åœ¨å¤„ç†æ–‡ä»¶: {docx_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(docx_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {docx_path}")
        return
    
    # ä» DOCX æ–‡ä»¶æå–æ–‡æœ¬
    print("ğŸ“– æ­£åœ¨ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬...")
    text_content = extract_text_from_docx(docx_path)
    
    if text_content is None:
        print("âŒ æ— æ³•æå– DOCX æ–‡ä»¶å†…å®¹")
        return
    
    print(f"âœ… æˆåŠŸæå–æ–‡æœ¬ï¼Œå…± {len(text_content)} ä¸ªå­—ç¬¦")
    
    # æŒ‰ç« èŠ‚æ¨¡å¼åˆ‡åˆ†æ–‡æ¡£
    print("âœ‚ï¸ æ­£åœ¨æŒ‰'ç¬¬ä¸€ç« \\näººç±»æ‚²ä¼¤çš„åŸå‹'æ ¼å¼åˆ‡åˆ†ç« èŠ‚...")
    chapters = split_chapters_by_pattern(text_content)

    print(f"âœ… æˆåŠŸè¯†åˆ«å‡º {len(chapters)} ä¸ªç« èŠ‚")
    print("=" * 80)
    print("ğŸ“‹ ç« èŠ‚åˆ‡åˆ†ç»“æœ:")
    print("=" * 80)
    
    group_chapters = {}
    index = 0
    current_page = 0
    for i, chapter in enumerate(chapters, 1):
        if chapter['title'] == "":
            continue

        title, page = get_title_and_page(chapter['title'])
        if title not in group_chapters:
            index += 1
            group_chapters[title] = {
                "title":  f"ç¬¬ {index} ç« : {title}",
            }

        if page > 0:
            current_page = page
        else:
            current_page = current_page + 2

        title = group_chapters[title]
        print(title['title'], current_page)
        get_ai_response_and_insert_data(title['title'], chapter['content'], current_page)

    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ€»è®¡: {len(chapters)} ä¸ªç« èŠ‚")
    total_chars = sum(len(ch['content']) for ch in chapters)
    print(f"æ€»å†…å®¹å­—ç¬¦æ•°: {total_chars}")
    
    # print("\nâ€”" * 80)
    # print("æ‰€æœ‰ç« èŠ‚æ ‡é¢˜åˆ—è¡¨:")
    # print("â€”" * 80)
    # for i, chapter in enumerate(chapters, 1):
    #     print(f"{i:3d}. {chapter['title']}")

def get_ai_response_and_insert_data(title, content, page):
    try:
        result_data = get_ai_response(content)
        if len(result_data) == 0:
            print("result_data is empty")
            return

        # print(result_data)
        batch_data = []
        # Process the new response format: result_data is a list of objects
        for item in result_data:
            content = item.get("content", "")
            relevant_age_group = item.get("relevant_age_group", "")
            relevant_domain = item.get("relevant_domain", "å…¶ä»–")
            tags = item.get("tags", [])

            # Convert single values to lists if needed
            if isinstance(relevant_age_group, str):
                relevant_age_group = (
                    [relevant_age_group] if relevant_age_group else []
                )
            if isinstance(relevant_domain, str):
                relevant_domain = [relevant_domain] if relevant_domain else []

            tags_json = json.dumps(tags, ensure_ascii=False)
            categories_json = json.dumps(relevant_domain, ensure_ascii=False)
            ages_json = json.dumps(relevant_age_group, ensure_ascii=False)
            summary = content  # Use the content as summary since that's where the main text is

            # Add data to batch list instead of inserting individually
            batch_data.append(
                (
                    "ä¾æ‹ä¸‰éƒ¨æ›²â€¢ç¬¬äºŒå·åˆ†ç¦»",
                    title,
                    summary,
                    "",
                    tags_json,
                    categories_json,
                    ages_json,
                    page,
                )
            )

    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æé”™è¯¯ for chapter {i}: {e}")
        print(f"AI response was: {result_data}")
        return
    except Exception as e:
        print(f"âŒ å¤„ç†ç« èŠ‚ {title} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return

    # Perform batch insertion
    if batch_data:
        from bookModel import batch_insert_data

        success = batch_insert_data(batch_data)
        if success:
            print(f"âœ… æ‰¹é‡æ’å…¥ {len(batch_data)} æ¡è®°å½•æˆåŠŸ")
        else:
            print("âŒ æ‰¹é‡æ’å…¥å¤±è´¥")
    else:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®éœ€è¦æ’å…¥")


if __name__ == "__main__":
    process_yilian_docx()